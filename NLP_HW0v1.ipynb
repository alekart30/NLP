{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_HW0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eeTtu3DL5bUF",
        "TK1JqiQU8MS0",
        "vc8JNECV8n1E",
        "RaHpWSat66zg"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4pvaeDpH4MEc"
      },
      "source": [
        "# Advanced NLP HW0\n",
        "\n",
        "Before starting the task please read thoroughly these chapters of Speech and Language Processing by Daniel Jurafsky & James H. Martin:\n",
        "\n",
        "•\tN-gram language models: https://web.stanford.edu/~jurafsky/slp3/3.pdf\n",
        "\n",
        "•\tNeural language models: https://web.stanford.edu/~jurafsky/slp3/7.pdf \n",
        "\n",
        "In this task you will be asked to implement the models described there.\n",
        "\n",
        "Build a text generator based on n-gram language model and neural language model.\n",
        "1.\tFind a corpus (e.g. http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt ), but you are free to use anything else of your interest\n",
        "2.\tPreprocess it if necessary (we suggest using nltk for that)\n",
        "3.\tBuild an n-gram model\n",
        "4.\tTry out different values of n, calculate perplexity on a held-out set\n",
        "5.\tBuild a simple neural network model for text generation (start from a feed-forward net for example). We suggest using tensorflow + keras for this task\n",
        "\n",
        "Criteria:\n",
        "1.\tData is split into train / validation / test, motivation for the split method is given\n",
        "2.\tN-gram model is implemented\n",
        "a.\tUnknown words are handled\n",
        "b.\tAdd-k Smoothing is implemented\n",
        "3.\tNeural network for text generation is implemented\n",
        "4.\tPerplexity is calculated for both models\n",
        "5.\tExamples of texts generated with different models are present and compared\n",
        "6.\tOptional: Try both character-based and word-based approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObQupt1QO0IT",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-K3RkIqbMMe",
        "colab_type": "text"
      },
      "source": [
        "We need nltk 3.4.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7yubCcBZlJ7",
        "colab_type": "code",
        "outputId": "40902b9e-c98c-4c3c-a2d0-eaa37f5da3af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "! pip uninstall nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling nltk-3.2.5:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/nltk-3.2.5.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/nltk/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled nltk-3.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aG3pTnNakgc",
        "colab_type": "code",
        "outputId": "13d020c4-8dcd-41f4-cc70-339bdb0b0ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "! pip install nltk==3.4.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 993kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5) (1.12.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449906 sha256=45004884269b5c19eced2331d78d57594bbe715fcfb90a046db7e586eeeba06e\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "Successfully installed nltk-3.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJT5gEEYarTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9GDvVAwas-K",
        "colab_type": "code",
        "outputId": "e0c115f5-3c8d-49b4-b5ab-3b68220d4c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "nltk.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzgHRjlO1ie",
        "colab_type": "code",
        "outputId": "b2e8ddf4-1b17-4021-f647-09b2bc99c4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import inflect\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm import NgramCounter\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkBo4SVuCURS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\") # Let's make sure GPU is available!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aE6Vd09OfQl",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QWnXjwINerb",
        "colab_type": "code",
        "outputId": "bf64cae3-a179-4a95-f73f-0b4984d603e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "! wget -c https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-03 21:30:36--  https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4573338 (4.4M) [text/plain]\n",
            "Saving to: ‘shakespeare_input.txt’\n",
            "\n",
            "shakespeare_input.t 100%[===================>]   4.36M  3.88MB/s    in 1.1s    \n",
            "\n",
            "2020-02-03 21:30:38 (3.88 MB/s) - ‘shakespeare_input.txt’ saved [4573338/4573338]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzEaADmVOxRL",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeTtu3DL5bUF",
        "colab_type": "text"
      },
      "source": [
        "##Loading text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXbdy-ihRtB5",
        "colab_type": "text"
      },
      "source": [
        "Read text as one string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqVRFv2UOyyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_file = open(\"shakespeare_input.txt\", \"r\")\n",
        "input_string = input_file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TtvjR5vTnQg",
        "colab_type": "text"
      },
      "source": [
        "Number of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nXQahbbRSkD",
        "colab_type": "code",
        "outputId": "6c09a8c1-003d-4c87-a338-350874e3f48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(input_string)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4573338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puGnXkxh8W1y",
        "colab_type": "code",
        "outputId": "98a390ad-e653-461a-d515-0486c3dd8c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "input_string[:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlJIoJsHXf-h",
        "colab_type": "text"
      },
      "source": [
        "Perpesent text as list of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMSWCWdXWHAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "text = sent_detector.tokenize(input_string.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97w4UzOUmHNn",
        "colab_type": "text"
      },
      "source": [
        "Make some replacement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gz7buptmLfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replacement_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\",\n",
        "                        \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                        \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
        "                        \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                        \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                        \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                        \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"I will\",\n",
        "                        \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"i'd\": \"i would\",\n",
        "                        \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\", \n",
        "                        \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
        "                        \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
        "                        \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
        "                        \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
        "                        \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n",
        "                        \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
        "                        \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
        "                        \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
        "                        \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
        "                        \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n",
        "                        \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\n",
        "                        \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
        "                        \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\",\n",
        "                        \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                        \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\",\n",
        "                        \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
        "                        \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
        "                        \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n",
        "                        \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\",\n",
        "                        \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
        "                        \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
        "                        \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\",\n",
        "                        \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
        "                        \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                        \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "                        \"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
        "                        \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
        "                        \"'t\": \" it\", \"'em\": \"them\", \"o'\": \"of\", \"'ll\": \" will\", \"ne'er\":\"never\", \"'ld\": \" would\", \"i'\": \"in\",\n",
        "                        \"'d\": \"ed\", \"'en \": \"ken \", \"'bout\":\"about\", \"'gainst\":\"against\", \"'scape\":\"escape\", \"'mongst\": \"amongst\", \n",
        "                        \"'n\": \"en\", \"e'er\":\"ever\", \"itwas\":\"it was\" }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUQ0HCLVQbdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_phrases(sentence, phrases_dict):\n",
        "  for key, value in phrases_dict.items():\n",
        "    sentence = sentence.replace(key, value)\n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-cmc3rl7hmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replacer = partial(replace_phrases, phrases_dict=replacement_dict)\n",
        "text = list(map(replacer, text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E0ukgT3Xkah",
        "colab_type": "text"
      },
      "source": [
        "Tokenize each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ZBBYW5WUTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_in_words = list(map(nltk.word_tokenize, text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHR1lazDT0OY",
        "colab_type": "text"
      },
      "source": [
        "We need to make normalization:\n",
        "\n",
        "*remove non ascii characters from words\n",
        "\n",
        "*to lower_case???\n",
        "\n",
        "*replace numbers\n",
        "\n",
        "*remove stopwords???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK1JqiQU8MS0",
        "colab_type": "text"
      },
      "source": [
        "##Basic preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dROX7Nf1Ty4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Mej41qWBuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9egm9mvTWDe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s\\<\\>\\/]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azQJn09RWeol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06stlrdMXIwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3MCt8LvYCQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_words(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word)\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc8JNECV8n1E",
        "colab_type": "text"
      },
      "source": [
        "## Using only some preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtZ3fB9ZX396",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = replace_numbers(words)\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EO6_zlU9F_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_in_words_normalized = list(map(normalize, text_in_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flyz5fpg9kY5",
        "colab_type": "text"
      },
      "source": [
        "Let's pad sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQz-lbj6X0bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padder(sentence):\n",
        "  return list(nltk.lm.preprocessing.pad_both_ends(sentence,n=2))\n",
        "text_in_words_padded = list(map(padder, text_in_words_normalized))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCVeFRYn9p7i",
        "colab_type": "code",
        "outputId": "9f60fbe1-0c19-4cec-abb8-562a9f3c1c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "text_in_words_padded[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'before',\n",
              " 'we',\n",
              " 'proceed',\n",
              " 'any',\n",
              " 'further',\n",
              " ',',\n",
              " 'hear',\n",
              " 'me',\n",
              " 'speak',\n",
              " '.',\n",
              " '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G69E_AlNmjzQ",
        "colab_type": "text"
      },
      "source": [
        "## All in one class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP8xCt9W97Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Preprocessor():\n",
        "\n",
        "  def __init__(self, filename, n):\n",
        "    self.__filename = filename\n",
        "    self.__n = n\n",
        "    self.__text_in_words = None\n",
        "    self.__replacement_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\",\n",
        "                        \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                        \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
        "                        \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                        \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                        \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                        \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"I will\",\n",
        "                        \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"i'd\": \"i would\",\n",
        "                        \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\", \n",
        "                        \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
        "                        \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
        "                        \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
        "                        \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
        "                        \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n",
        "                        \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
        "                        \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
        "                        \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
        "                        \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
        "                        \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n",
        "                        \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\n",
        "                        \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
        "                        \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\",\n",
        "                        \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                        \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\",\n",
        "                        \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
        "                        \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
        "                        \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n",
        "                        \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\",\n",
        "                        \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
        "                        \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
        "                        \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\",\n",
        "                        \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
        "                        \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                        \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "                        \"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
        "                        \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
        "                        \"'t\": \" it\", \"'em\": \"them\", \"o'\": \"of\", \"'ll\": \" will\", \"ne'er\":\"never\", \"'ld\": \" would\", \"i'\": \"in\",\n",
        "                        \"'d\": \"ed\", \"'en \": \"ken \", \"'bout\":\"about\", \"'gainst\":\"against\", \"'scape\":\"escape\", \"'mongst\": \"amongst\", \n",
        "                        \"'n\": \"en\", \"e'er\":\"ever\", \"itwas\":\"it was\" }\n",
        "  \n",
        "  def __tokenize(self):\n",
        "    # read raw text\n",
        "    input_file = open(self.__filename, \"r\")\n",
        "    input_string = input_file.read()\n",
        "    # split by sentences\n",
        "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    text = sent_detector.tokenize(input_string.strip())\n",
        "\n",
        "    def replace_phrases(sentence, phrases_dict):\n",
        "      # replace sentences accordingly to given dictionary\n",
        "      for key, value in phrases_dict.items():\n",
        "        sentence = sentence.replace(key, value)\n",
        "      return sentence\n",
        "    \n",
        "    # replace sentences accordingly to given dictionary\n",
        "    replacer = partial(replace_phrases, phrases_dict=self.__replacement_dict)\n",
        "    text = list(map(replacer, text))\n",
        "    # tokenize each sentence into words\n",
        "    self.__text_in_words = list(map(nltk.word_tokenize, text))\n",
        "\n",
        "  def __normalize(self):\n",
        "\n",
        "    def normalize_sentence(words):\n",
        "      def remove_non_ascii(words):\n",
        "        \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "        new_words = []\n",
        "        for word in words:\n",
        "            new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "            new_words.append(new_word)\n",
        "        return new_words\n",
        "\n",
        "      def to_lowercase(words):\n",
        "        \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "        new_words = []\n",
        "        for word in words:\n",
        "            new_word = word.lower()\n",
        "            new_words.append(new_word)\n",
        "        return new_words\n",
        "      \n",
        "      def replace_numbers(words):\n",
        "        \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "        p = inflect.engine()\n",
        "        new_words = []\n",
        "        for word in words:\n",
        "            if word.isdigit():\n",
        "                new_word = p.number_to_words(word)\n",
        "                new_words.append(new_word)\n",
        "            else:\n",
        "                new_words.append(word)\n",
        "        return new_words\n",
        "\n",
        "      words = remove_non_ascii(words)\n",
        "      words = to_lowercase(words)\n",
        "      words = replace_numbers(words)\n",
        "      return words\n",
        "    # normalized each sentence\n",
        "    text_in_words_normalized = list(map(normalize_sentence, self.__text_in_words))\n",
        "\n",
        "    def padder(sentence):\n",
        "      return list(nltk.lm.preprocessing.pad_both_ends(sentence,n=self.__n))\n",
        "    # pad each sentence from begging and end by special characters <s> </s>\n",
        "    text_in_words_padded = list(map(padder, text_in_words_normalized))\n",
        "    return text_in_words_padded\n",
        "\n",
        "  def preprocess(self):\n",
        "    self.__tokenize()\n",
        "    return self.__normalize()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_LN84z-AOLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessor = Preprocessor(\"shakespeare_input.txt\", n=5)\n",
        "full_text = preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dRFb0IEAoLa",
        "colab_type": "code",
        "outputId": "d07be817-bd50-49dc-9162-04f445358f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(full_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHtYfeAbAq08",
        "colab_type": "code",
        "outputId": "b81f24dd-b89d-4c9f-8d30-89418a922734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(text_in_words_padded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m7FEwRuO6og0"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7HWfry45gdt",
        "colab_type": "text"
      },
      "source": [
        "##N gram model with k-add smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xWBs4AoC4JfO",
        "colab": {}
      },
      "source": [
        "class NgramModel:\n",
        "  def __init__(self, n, k, vocab = None):\n",
        "    \"\"\"Language model constructor\n",
        "    n -- n-gram size\n",
        "    vocab -- optional fixed vocabulary for the model\n",
        "    \"\"\"\n",
        "    self.n = n\n",
        "    self.vocab = vocab\n",
        "    self.k = k\n",
        "\n",
        "  def prob(self, word, context=None):\n",
        "    \"\"\"This method returns probability of a word with given context: P(w_t | w_{t - 1}...w_{t - n + 1})\n",
        "    \n",
        "    For example:\n",
        "    >>> lm.prob('hello', context=('world',))\n",
        "    0.99988\n",
        "    \"\"\"\n",
        "    return (self.text_ngrams[tuple(context)+(word,)] + self.k) / (self.text_n_minus_one_grams[tuple(context)] + self.k*len(self.vocab))\n",
        "    \n",
        "\n",
        "  def generate_text(self, text_length):\n",
        "    \"\"\"This method generates random text of length \n",
        "    \n",
        "    For example\n",
        "    >>> lm.generate_text(2)\n",
        "    hello world\n",
        "\n",
        "    \"\"\"\n",
        "    # we begin from <s><s>... n-1 times\n",
        "    text = ['<s>'] * (self.n-1)\n",
        "    for j in range(text_length):\n",
        "      # evaluate probabilities of each word for current context\n",
        "      probs = np.zeros(shape=(len(self.vocab)))\n",
        "      for i, word in enumerate(self.vocab):\n",
        "        probs[i] = self.prob(word=word, context=text[j:])\n",
        "      # normalize probabilitities due to some computational issues\n",
        "      probs = np.asarray(probs).astype('float64')\n",
        "      probs = probs / np.sum(probs)\n",
        "      # generate word index accordingly to distribution\n",
        "      rv = np.random.multinomial(1, probs, 1)\n",
        "      idx = rv.argmax()\n",
        "      # add word to text\n",
        "      text.append(self.vocab[idx])\n",
        "    # postprocess generated text\n",
        "    str_text = ' '. join(text)\n",
        "    str_text = str_text.replace('<s> ', \"\")\n",
        "    str_text = str_text.replace(' </s>', \"\")\n",
        "    return str_text\n",
        "\n",
        "  def update(self, sequence_of_tokens):\n",
        "    \"\"\"This method learns probabiities based on given sequence of tokents\n",
        "    \n",
        "    sequence_of_tokens -- iterable of tokens\n",
        "\n",
        "    For example\n",
        "    >>> lm.update(['hello', 'world'])\n",
        "    \"\"\"\n",
        "    self.text_ngrams = Counter(ngrams(sequence_of_tokens, self.n))\n",
        "    self.text_n_minus_one_grams = Counter(ngrams(sequence_of_tokens, self.n-1))\n",
        "    self.vocab = list(set(sequence_of_tokens))\n",
        "    \n",
        "  def perplexity(self, sequence_of_tokens):\n",
        "    \"\"\"This method returns perplexity for a given sequence of tokens\n",
        "    \n",
        "    sequence_of_tokens -- iterable of tokens\n",
        "    \"\"\"\n",
        "    log_prob = 0\n",
        "    for i in range(n-1,len(sequence_of_tokens)):\n",
        "      log_prob += np.log(self.prob(word=sequence_of_tokens[i],\n",
        "                                   context=sequence_of_tokens[i-(n-1):i]))\n",
        "    return np.exp(-log_prob/len(sequence_of_tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FURKDw6l5sTl",
        "colab_type": "text"
      },
      "source": [
        "Load text and split it into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utm07tZvECIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(full_text, train_fraction, val_fraction):\n",
        "  length = len(full_text)\n",
        "  train, val, test = full_text[:int(train_fraction*length)],\\\n",
        "                     full_text[int(train_fraction*length):int((train_fraction+val_fraction)*length)],\\\n",
        "                     full_text[int((train_fraction+val_fraction)*length):]\n",
        "  train_text, val_text, test_text = [], [], []\n",
        "  for sentence in train:\n",
        "    train_text += sentence\n",
        "  for sentence in val:\n",
        "    val_text += sentence\n",
        "  for sentence in test:\n",
        "    test_text += sentence\n",
        "  return train_text, val_text, test_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH-LEbk55w2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 5\n",
        "preprocessor = Preprocessor(\"shakespeare_input.txt\", n=n)\n",
        "full_text = preprocessor.preprocess()\n",
        "# train/test split\n",
        "train_text, val_text, test_text = split(full_text, 0.5, 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKFAJUTFYpJy",
        "colab_type": "code",
        "outputId": "9b55b43a-fc5d-4fac-b4b3-017a53d2a884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "model = NgramModel(n=n,k=1)\n",
        "model.update(train_text)\n",
        "print(model.perplexity(val_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2652.3228435544115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J21vit1y7R-b",
        "colab_type": "text"
      },
      "source": [
        "Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF1pUoYf7iJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perplexity_list = []\n",
        "for n in range(2,7):\n",
        "  preprocessor = Preprocessor(\"shakespeare_input.txt\", n=n)\n",
        "  full_text = preprocessor.preprocess()\n",
        "  # train/test split\n",
        "  train_text, val_text, test_text = split(full_text, 0.5, 0.3)\n",
        "  \n",
        "  model = NgramModel(n=n,k=1)\n",
        "  model.update(train_text)\n",
        "  perplexity_list.append(model.perplexity(val_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow85OUYx86nJ",
        "colab_type": "code",
        "outputId": "dbd2ad13-a3f9-483c-9a95-74c4360afdff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.plot(list(range(2,7)), perplexity_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3e48cb6b00>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0TfGmCDy/wHZfJpr717ArAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbN5jDMQZgzd",
        "colab_type": "text"
      },
      "source": [
        "We choose model with minimal perplexity, which implies maximum probability of validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn_lAW3JZqjW",
        "colab_type": "code",
        "outputId": "2b6dc694-8de1-42fd-b4ca-195a8f06294a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "n = 2\n",
        "preprocessor = Preprocessor(\"shakespeare_input.txt\", n=n)\n",
        "full_text = preprocessor.preprocess()\n",
        "# train/test split\n",
        "train_text, val_text, test_text = split(full_text, 0.5, 0.3)\n",
        "model = NgramModel(n=n,k=1)\n",
        "model.update(train_text)\n",
        "print(model.perplexity(test_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1117.6749768007317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHIyiD-N_Wcg",
        "colab_type": "text"
      },
      "source": [
        "## Neural model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaHpWSat66zg",
        "colab_type": "text"
      },
      "source": [
        "## Observe training process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qotmDlbZ5UD",
        "colab_type": "text"
      },
      "source": [
        "These part is for debugging of neural network training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSWUsfAg-cyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 5\n",
        "preprocessor = Preprocessor(\"shakespeare_input.txt\", n=n)\n",
        "full_text = preprocessor.preprocess()\n",
        "# train/test split\n",
        "length = len(full_text)\n",
        "train, val, test = full_text[:int(0.5*length)], full_text[int(0.5*length):int(0.8*length)], full_text[int(0.8*length):]\n",
        "# merge sentences in one text(list)\n",
        "train_text, val_text, test_text = [], [], []\n",
        "for sentence in train:\n",
        "  train_text += sentence\n",
        "for sentence in val:\n",
        "  val_text += sentence\n",
        "for sentence in test:\n",
        "  test_text += sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncK5gHqh-2uF",
        "colab_type": "text"
      },
      "source": [
        "Add 'unk' to handle unknown words during inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMm8u9EVLCaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words = list(set(train_text))\n",
        "unique_words.append('unk')\n",
        "voc_size = len(unique_words)\n",
        "word_to_id = {word:i for i, word in enumerate(unique_words)}\n",
        "id_to_word = {i:word for word, i in word_to_id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBcoAwRQsGoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_samples(text, n, word_to_id):\n",
        "  X, y = [], []\n",
        "  number_of_samples = len(text) - n + 1\n",
        "  for i in range(number_of_samples):\n",
        "    X.append(np.array([word_to_id.get(word, word_to_id['unk']) for word in text[i:i+n-1]]))\n",
        "    y.append(np.array(word_to_id.get(text[i+n-1], word_to_id['unk'])))\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "  return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP847NU-vLt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = construct_samples(train_text, n, word_to_id)\n",
        "X_val, y_val = construct_samples(val_text, n, word_to_id)\n",
        "X_test, y_test = construct_samples(test_text, n, word_to_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZAg6KH0oZxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flattener(nn.Module):\n",
        "    def forward(self, x):\n",
        "      batch_size, *_ = x.shape\n",
        "      return x.view(batch_size, -1)\n",
        "\n",
        "nn_model = nn.Sequential(\n",
        "            nn.Embedding(voc_size, 10),\n",
        "            Flattener(),\n",
        "            nn.Linear((n-1)*10, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(100, voc_size),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGAJ1fQHqL0C",
        "colab_type": "code",
        "outputId": "66c40e2b-d9f5-4ff5-c263-67046290fb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "nn_model.type(torch.cuda.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Embedding(17898, 10)\n",
              "  (1): Flattener()\n",
              "  (2): Linear(in_features=40, out_features=100, bias=True)\n",
              "  (3): ReLU(inplace=True)\n",
              "  (4): Linear(in_features=100, out_features=17898, bias=True)\n",
              "  (5): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq-XCxGvqpSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = nn.NLLLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.SGD(nn_model.parameters(), lr=1e-2, weight_decay=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drvTcFVBEHwf",
        "colab_type": "code",
        "outputId": "14f8b3c0-43db-421d-cc80-c198b372c97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "train_subset_size = 10000\n",
        "val_subset_size = 2000\n",
        "batch_size = 1000\n",
        "train_losses, val_losses = [], []\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.2)\n",
        "\n",
        "for epoch in range(70):\n",
        "  total_train_loss, total_val_loss = 0, 0\n",
        "  # enter train mode\n",
        "  nn_model.train()\n",
        "  # create random subset of train data\n",
        "  indices = list(range(X_train.shape[0]))\n",
        "  chosen_indices = np.random.choice(indices,train_subset_size)\n",
        "  X,y = X_train[chosen_indices,:], y_train[chosen_indices]\n",
        "  # train by batches\n",
        "  for i in range(train_subset_size // batch_size):\n",
        "    # create batch and send to GPU\n",
        "    context_idxs = torch.tensor(X[i:(i+1)*batch_size, :], dtype=torch.long)\n",
        "    y_gpu = torch.tensor(y[i:(i+1)*batch_size], dtype=torch.long).to(device)\n",
        "    x_gpu = context_idxs.to(device)\n",
        "    # delete previously accumulated gradients\n",
        "    nn_model.zero_grad()\n",
        "    # calc log probs\n",
        "    log_probs = nn_model(x_gpu)\n",
        "    # calc loss\n",
        "    loss = loss_function(log_probs, y_gpu)\n",
        "    # perform backward pass and update weights\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # calculate total loss\n",
        "    total_train_loss += loss.item() \n",
        "    \n",
        "  # enter evaluation mode\n",
        "  nn_model.eval()\n",
        "  # create random subset of train data\n",
        "  indices = list(range(X_val.shape[0]))\n",
        "  chosen_indices = np.random.choice(indices,val_subset_size)\n",
        "  X,y = X_val[chosen_indices,:], y_val[chosen_indices]\n",
        "\n",
        "  for i in range(val_subset_size // batch_size):\n",
        "    # create batch and send to GPU\n",
        "    context_idxs = torch.tensor(X[i:(i+1)*batch_size, :], dtype=torch.long)\n",
        "    y_gpu = torch.tensor(y[i:(i+1)*batch_size], dtype=torch.long).to(device)\n",
        "    x_gpu = context_idxs.to(device)\n",
        "    # calc log probs\n",
        "    log_probs = nn_model(x_gpu)\n",
        "    loss = loss_function(log_probs, y_gpu)\n",
        "    # calculate total loss\n",
        "    total_val_loss += loss.item() \n",
        "\n",
        "  print('Average train loss {}, average validation loss {}'.format(total_train_loss/train_subset_size, total_val_loss/val_subset_size))\n",
        "  train_losses.append(total_train_loss/train_subset_size)\n",
        "  val_losses.append(total_val_loss/val_subset_size)\n",
        "  scheduler.step()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b886074561a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# perform backward pass and update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# calculate total loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.27 GiB (GPU 0; 15.90 GiB total capacity; 9.83 GiB already allocated; 1.52 GiB free; 3.85 GiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWnxHlVswztL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdiuDapu0cQ4",
        "colab_type": "code",
        "outputId": "8690eaff-4172-4898-c6f4-871811b9e9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "nn_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Embedding(17898, 10)\n",
              "  (1): Flattener()\n",
              "  (2): Linear(in_features=40, out_features=100, bias=True)\n",
              "  (3): ReLU(inplace=True)\n",
              "  (4): Linear(in_features=100, out_features=17898, bias=True)\n",
              "  (5): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C01phXvM0wk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_model.eval()\n",
        "full_prob = 0\n",
        "for context, word in zip(X_test, y_test):\n",
        "  #print(context.shape)\n",
        "  context_idxs = torch.tensor(context.reshape(1,-1), dtype=torch.long)\n",
        "  x_gpu = context_idxs.to(device)   \n",
        "  log_probs = nn_model(x_gpu).cpu().detach().numpy()\n",
        "  #print(log_probs)\n",
        "  prob = log_probs[0,word_to_id.get(word, word_to_id['unk'])]\n",
        "  #print(prob)\n",
        "  full_prob += prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZSAgasg5qln",
        "colab_type": "code",
        "outputId": "d307b750-52b9-4034-ebdf-28982bf7d85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "full_prob"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3083277.9077386856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5tDfaY450nV",
        "colab_type": "code",
        "outputId": "086a7f49-af1c-4520-c3d8-55dea9589acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.exp(-full_prob/len(test_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27569.349679585583"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akmv9KnQSDm_",
        "colab_type": "code",
        "outputId": "dcade30a-9693-40e2-8a19-385a13cfcd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(range(len(val_losses)), val_losses)\n",
        "plt.plot(range(len(val_losses)), train_losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6d2e095668>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ASackgH7AJ3",
        "colab_type": "text"
      },
      "source": [
        "## Neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQBzPLNN7U2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 5\n",
        "preprocessor = Preprocessor(\"shakespeare_input.txt\", n=n)\n",
        "full_text = preprocessor.preprocess()\n",
        "# train/test split\n",
        "train_text, val_text, test_text = split(full_text, 0.5, 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ZZJCkW7EWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralModel:\n",
        "  def __init__(self, n, vocab = None):\n",
        "    \"\"\"Language model constructor\n",
        "    n -- n-gram size\n",
        "    vocab -- optional fixed vocabulary for the model\n",
        "    \"\"\"\n",
        "    self.n = n\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def log_prob(self, word, context=None):\n",
        "    \"\"\"This method returns probability of a word with given context: P(w_t | w_{t - 1}...w_{t - n + 1})\n",
        "    \n",
        "    For example:\n",
        "    >>> lm.prob('hello', context=('world',))\n",
        "    0.99988\n",
        "    \"\"\"\n",
        "    self.nn_model.eval()\n",
        "    context = np.array([self.word_to_id.get(word, self.word_to_id['unk']) for word in context])\n",
        "    context_idxs = torch.tensor(context.reshape(1,-1), dtype=torch.long)\n",
        "    x_gpu = context_idxs.to(device)   \n",
        "    log_probs = self.nn_model(x_gpu).cpu().detach().numpy()\n",
        "    return log_probs[0,self.word_to_id.get(word, self.word_to_id['unk'])]\n",
        "    \n",
        "    \n",
        "\n",
        "  def generate_text(self, text_length):\n",
        "    \"\"\"This method generates random text of length \n",
        "    \n",
        "    For example\n",
        "    >>> lm.generate_text(2)\n",
        "    hello world\n",
        "\n",
        "    \"\"\"\n",
        "    # we begin from <s><s>... n-1 times\n",
        "    text = ['<s>'] * (self.n-1)\n",
        "    for j in range(text_length):\n",
        "      # evaluate probabilities of each word for current context\n",
        "      probs = np.zeros(shape=(len(self.vocab)))\n",
        "      for i, word in enumerate(self.vocab):\n",
        "        probs[i] = np.exp(self.log_prob(word=word, context=text[j:]))\n",
        "      # normalize probabilitities due to some computational issues\n",
        "      probs = np.asarray(probs).astype('float64')\n",
        "      probs = probs / np.sum(probs)\n",
        "      # generate word index accordingly to distribution\n",
        "      rv = np.random.multinomial(1, probs, 1)\n",
        "      idx = rv.argmax()\n",
        "      # add word to text\n",
        "      text.append(self.vocab[idx])\n",
        "    # postprocess generated text\n",
        "    str_text = ' '. join(text)\n",
        "    str_text = str_text.replace('<s> ', \"\")\n",
        "    str_text = str_text.replace(' </s>', \"\")\n",
        "    return str_text\n",
        "  \n",
        "  @staticmethod\n",
        "  def construct_samples(text, n, word_to_id):\n",
        "      X, y = [], []\n",
        "      number_of_samples = len(text) - n + 1\n",
        "      for i in range(number_of_samples):\n",
        "        X.append(np.array([word_to_id.get(word, word_to_id['unk']) for word in text[i:i+n-1]]))\n",
        "        y.append(np.array(word_to_id.get(text[i+n-1], word_to_id['unk'])))\n",
        "      X = np.array(X)\n",
        "      y = np.array(y)\n",
        "      return X, y\n",
        "\n",
        "  def update(self, sequence_of_tokens, val_sequence):\n",
        "    \"\"\"This method learns probabiities based on given sequence of tokents\n",
        "    \n",
        "    sequence_of_tokens -- iterable of tokens\n",
        "\n",
        "    For example\n",
        "    >>> lm.update(['hello', 'world'])\n",
        "    \"\"\"\n",
        "    self.vocab = list(set(sequence_of_tokens))\n",
        "    self.vocab.append('unk')\n",
        "    self.voc_size = len(self.vocab)\n",
        "    self.word_to_id = {word:i for i, word in enumerate(self.vocab)}\n",
        "    self.id_to_word = {i:word for word, i in self.word_to_id.items()}\n",
        "\n",
        "    X_train, y_train = NeuralModel.construct_samples(sequence_of_tokens, self.n, self.word_to_id)\n",
        "    X_val, y_val = NeuralModel.construct_samples(val_sequence, self.n, self.word_to_id)\n",
        "\n",
        "    \n",
        "    # prepare network\n",
        "    class Flattener(nn.Module):\n",
        "      def forward(self, x):\n",
        "        batch_size, *_ = x.shape\n",
        "        return x.view(batch_size, -1)\n",
        "\n",
        "    self.nn_model = nn.Sequential(\n",
        "              nn.Embedding(self.voc_size, 10),\n",
        "              Flattener(),\n",
        "              nn.Linear((self.n-1)*10, 100),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.Linear(100, self.voc_size),\n",
        "              nn.LogSoftmax(dim=1)\n",
        "          )\n",
        "    self.nn_model.type(torch.cuda.FloatTensor)\n",
        "    loss_function = nn.NLLLoss().type(torch.cuda.FloatTensor)\n",
        "    optimizer = optim.SGD(self.nn_model.parameters(), lr=1e-2, weight_decay=1e-3)\n",
        "    self.train_network(optimizer, loss_function, X_train, y_train, X_val, y_val)\n",
        "  \n",
        "  def train_network(self, optimizer, loss_function, X_train, y_train, X_val, y_val):\n",
        "    train_subset_size = 10000\n",
        "    val_subset_size = 2000\n",
        "    batch_size = 1000\n",
        "    train_losses, val_losses = [], []\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.2)\n",
        "\n",
        "    for epoch in range(70):\n",
        "      total_train_loss, total_val_loss = 0, 0\n",
        "      # enter train mode\n",
        "      self.nn_model.train()\n",
        "      # create random subset of train data\n",
        "      indices = list(range(X_train.shape[0]))\n",
        "      chosen_indices = np.random.choice(indices,train_subset_size)\n",
        "      X,y = X_train[chosen_indices,:], y_train[chosen_indices]\n",
        "      # train by batches\n",
        "      for i in range(train_subset_size // batch_size):\n",
        "        # create batch and send to GPU\n",
        "        context_idxs = torch.tensor(X[i:(i+1)*batch_size, :], dtype=torch.long)\n",
        "        y_gpu = torch.tensor(y[i:(i+1)*batch_size], dtype=torch.long).to(device)\n",
        "        x_gpu = context_idxs.to(device)\n",
        "        # delete previously accumulated gradients\n",
        "        self.nn_model.zero_grad()\n",
        "        # calc log probs\n",
        "        log_probs = self.nn_model(x_gpu)\n",
        "        # calc loss\n",
        "        loss = loss_function(log_probs, y_gpu)\n",
        "        # perform backward pass and update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # calculate total loss\n",
        "        total_train_loss += loss.item() \n",
        "        \n",
        "      # enter evaluation mode\n",
        "      self.nn_model.eval()\n",
        "      # create random subset of train data\n",
        "      indices = list(range(X_val.shape[0]))\n",
        "      chosen_indices = np.random.choice(indices,val_subset_size)\n",
        "      X,y = X_val[chosen_indices,:], y_val[chosen_indices]\n",
        "\n",
        "      for i in range(val_subset_size // batch_size):\n",
        "        # create batch and send to GPU\n",
        "        context_idxs = torch.tensor(X[i:(i+1)*batch_size, :], dtype=torch.long)\n",
        "        y_gpu = torch.tensor(y[i:(i+1)*batch_size], dtype=torch.long).to(device)\n",
        "        x_gpu = context_idxs.to(device)\n",
        "        # calc log probs\n",
        "        log_probs = self.nn_model(x_gpu)\n",
        "        loss = loss_function(log_probs, y_gpu)\n",
        "        # calculate total loss\n",
        "        total_val_loss += loss.item() \n",
        "\n",
        "      print('Average train loss {}, average validation loss {}'.format(total_train_loss/train_subset_size, total_val_loss/val_subset_size))\n",
        "      train_losses.append(total_train_loss/train_subset_size)\n",
        "      val_losses.append(total_val_loss/val_subset_size)\n",
        "      scheduler.step()\n",
        "\n",
        "  def perplexity(self, sequence_of_tokens):\n",
        "    \"\"\"This method returns perplexity for a given sequence of tokens\n",
        "    \n",
        "    sequence_of_tokens -- iterable of tokens\n",
        "    \"\"\"\n",
        "    log_prob = 0\n",
        "    for i in range(n-1,len(sequence_of_tokens)):\n",
        "      log_prob += self.log_prob(word=sequence_of_tokens[i],\n",
        "                                   context=sequence_of_tokens[i-(n-1):i])\n",
        "    return np.exp(-log_prob/len(sequence_of_tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Psr8nRBaSs",
        "colab_type": "code",
        "outputId": "0311c303-d841-44c9-a4a7-88abd4626351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model = NeuralModel(n=n)\n",
        "model.update(train_text, val_text)\n",
        "print(model.perplexity(test_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average train loss 0.009770707321166992, average validation loss 0.009739654064178467\n",
            "Average train loss 0.009715864849090577, average validation loss 0.009669081687927246\n",
            "Average train loss 0.009656036567687988, average validation loss 0.009610511302947999\n",
            "Average train loss 0.009592117023468018, average validation loss 0.009576213359832764\n",
            "Average train loss 0.009550999450683594, average validation loss 0.009498851776123047\n",
            "Average train loss 0.009472842693328858, average validation loss 0.009441829204559327\n",
            "Average train loss 0.009421945095062256, average validation loss 0.009393834590911865\n",
            "Average train loss 0.009351820278167725, average validation loss 0.009303159713745117\n",
            "Average train loss 0.009285266494750977, average validation loss 0.009250799179077148\n",
            "Average train loss 0.009247965908050538, average validation loss 0.009233259201049804\n",
            "Average train loss 0.009242447090148926, average validation loss 0.009225929260253906\n",
            "Average train loss 0.009231700801849365, average validation loss 0.009279324531555175\n",
            "Average train loss 0.009215861415863037, average validation loss 0.009187841415405273\n",
            "Average train loss 0.009183652591705322, average validation loss 0.009152101039886475\n",
            "Average train loss 0.009176928043365479, average validation loss 0.00911851167678833\n",
            "Average train loss 0.009180270385742187, average validation loss 0.009165964603424072\n",
            "Average train loss 0.009139041805267334, average validation loss 0.009149905681610107\n",
            "Average train loss 0.009120418071746825, average validation loss 0.009150221347808837\n",
            "Average train loss 0.009117572402954102, average validation loss 0.009147700786590576\n",
            "Average train loss 0.009116428661346435, average validation loss 0.009124385833740234\n",
            "Average train loss 0.009101767730712891, average validation loss 0.009101768970489503\n",
            "Average train loss 0.00912325963973999, average validation loss 0.009070661067962647\n",
            "Average train loss 0.009109453582763672, average validation loss 0.009122069835662841\n",
            "Average train loss 0.00912503423690796, average validation loss 0.009144941806793212\n",
            "Average train loss 0.009106515502929688, average validation loss 0.009090822219848632\n",
            "Average train loss 0.009127903079986573, average validation loss 0.009034150123596192\n",
            "Average train loss 0.009088460063934326, average validation loss 0.009081591129302978\n",
            "Average train loss 0.009101858234405518, average validation loss 0.00912026309967041\n",
            "Average train loss 0.009094401836395264, average validation loss 0.00908341360092163\n",
            "Average train loss 0.009110766315460206, average validation loss 0.00909663200378418\n",
            "Average train loss 0.00911801929473877, average validation loss 0.009085335731506348\n",
            "Average train loss 0.009119724750518799, average validation loss 0.009105276584625245\n",
            "Average train loss 0.009077265644073487, average validation loss 0.009052150249481201\n",
            "Average train loss 0.009086451816558839, average validation loss 0.00911411476135254\n",
            "Average train loss 0.0091205828666687, average validation loss 0.009101679801940918\n",
            "Average train loss 0.009130084705352783, average validation loss 0.009092004776000976\n",
            "Average train loss 0.009108929634094239, average validation loss 0.009132410526275635\n",
            "Average train loss 0.00909937744140625, average validation loss 0.009131932258605957\n",
            "Average train loss 0.009126048278808594, average validation loss 0.009117875099182129\n",
            "Average train loss 0.009108307361602784, average validation loss 0.009128997325897217\n",
            "Average train loss 0.009134290409088135, average validation loss 0.009109950065612793\n",
            "Average train loss 0.009108180141448975, average validation loss 0.00913357400894165\n",
            "Average train loss 0.009118785476684571, average validation loss 0.009122306346893311\n",
            "Average train loss 0.009109414577484131, average validation loss 0.009012279987335205\n",
            "Average train loss 0.009084173774719238, average validation loss 0.009127806663513184\n",
            "Average train loss 0.009106284046173096, average validation loss 0.009054944038391114\n",
            "Average train loss 0.009122076988220216, average validation loss 0.009066616535186768\n",
            "Average train loss 0.009088149833679199, average validation loss 0.009040302753448486\n",
            "Average train loss 0.009108526611328126, average validation loss 0.009123863220214844\n",
            "Average train loss 0.009076222133636475, average validation loss 0.009084926128387452\n",
            "Average train loss 0.009112259387969971, average validation loss 0.00904768419265747\n",
            "Average train loss 0.009106846618652343, average validation loss 0.009086694240570068\n",
            "Average train loss 0.009123739814758301, average validation loss 0.009040067672729492\n",
            "Average train loss 0.009104028701782226, average validation loss 0.009123315334320068\n",
            "Average train loss 0.009107329082489013, average validation loss 0.009098816394805908\n",
            "Average train loss 0.009112041473388672, average validation loss 0.009081599235534667\n",
            "Average train loss 0.00912725248336792, average validation loss 0.009132243633270264\n",
            "Average train loss 0.009128128623962402, average validation loss 0.009074146270751954\n",
            "Average train loss 0.00911574649810791, average validation loss 0.009100633144378662\n",
            "Average train loss 0.0091060866355896, average validation loss 0.009040284156799316\n",
            "Average train loss 0.009110114192962647, average validation loss 0.009093471050262451\n",
            "Average train loss 0.009099807834625244, average validation loss 0.009065906047821044\n",
            "Average train loss 0.00912049789428711, average validation loss 0.009043176651000977\n",
            "Average train loss 0.00909509792327881, average validation loss 0.009109918117523194\n",
            "Average train loss 0.009108895874023437, average validation loss 0.009041625022888184\n",
            "Average train loss 0.009090291404724121, average validation loss 0.009070644855499268\n",
            "Average train loss 0.009134163475036622, average validation loss 0.009058165550231933\n",
            "Average train loss 0.009087813663482667, average validation loss 0.009067556858062743\n",
            "Average train loss 0.009106706809997558, average validation loss 0.009133805274963379\n",
            "Average train loss 0.009101484775543213, average validation loss 0.009096466064453124\n",
            "9203.763065729423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTNuCVSbJ3lc",
        "colab_type": "code",
        "outputId": "378168b2-6aab-471a-dada-22e7fa3ba242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(model.generate_text(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beggared pink ranges overwhelming bowed stoics discontents wretches me mitigate\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}